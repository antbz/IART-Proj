{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covid Symptom Identification\n",
    "\n",
    "Project developed by:\n",
    "\n",
    "- Ana Teresa Cruz (up201806460)\n",
    "- André Nascimento (up201806461)\n",
    "- António Bezerra (up201806854)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.read_csv('large_data.csv')\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "dataset_corr = dataset.corr()\n",
    "plt.figure(figsize=(30,30))\n",
    "sb.heatmap(dataset_corr, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All data hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.hist(bins=[-0.05, 0.05, 0.95, 1.05], range=(0,1), figsize=(22, 16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allergy data hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allergy_data = dataset.loc[dataset['TYPE'] == 'ALLERGY']\n",
    "allergy_data.hist(bins=[-0.05, 0.05, 0.95, 1.05], range=(0,1), figsize=(22,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cold data hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cold_data = dataset.loc[dataset['TYPE'] == 'COLD']\n",
    "cold_data.hist(bins=[-0.05, 0.05, 0.95, 1.05], range=(0,1), figsize=(22,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covid data hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_data = dataset.loc[dataset['TYPE'] == 'COVID']\n",
    "covid_data.hist(bins=[-0.05, 0.05, 0.95, 1.05], range=(0,1), figsize=(22,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flu data hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_data = dataset.loc[dataset['TYPE'] == 'FLU']\n",
    "flu_data.hist(bins=[-0.05, 0.05, 0.95, 1.05], range=(0,1), figsize=(22,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "Since our dataset did not contain null or invalid values or significant outliers, we did not have much preprocessing work to do. The only manipulation we did was split the dataset into input and label sets so that they could be passed to the SciKit classifiers we use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['TYPE'] = dataset['TYPE'].astype('category')\n",
    "\n",
    "col_names = list(dataset.columns)\n",
    "col_names.remove('TYPE')\n",
    "\n",
    "inputs = dataset[col_names].values\n",
    "labels = dataset['TYPE'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and Test split data\n",
    "\n",
    "We used SciKit's built-in train_test_split function in order to generate train and test datasets. We defined the trainig data as 1/4 of the entire dataset. We use the stratify option in order to maintain the original dataset's class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(train_in,\n",
    " test_in,\n",
    " train_classes,\n",
    " test_classes) = train_test_split(inputs, labels, test_size=0.25, random_state=1, stratify=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling\n",
    "\n",
    "Our data analysis stage showed that our working dataset was heavily inbalanced. (inserir percentagens)\n",
    "\n",
    "Early exploratory analysis of classification methods proved that this was having a negative effect on the accuracy of the classifier, especially for the minority classes. To solve this problem we implemented resampling techniques that would generate a more balanced training set.\n",
    "\n",
    "We implemented both **undersampling** and **oversampling**. These techniques differ in that undersampling removes samples from majority categories, while oversampling duplicates samples from minority categories. Oversampling is generally preffered, but undersampling generates smaller and therefore less complex datasets.\n",
    "\n",
    "We used random over and undersampling techniques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"---Train Set---\")\n",
    "print(Counter(train_classes))\n",
    "print(\"\\n---Test Set---\")\n",
    "print(Counter(test_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "us_inputs, us_labels = rus.fit_resample(train_in, train_classes)\n",
    "\n",
    "print(Counter(us_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "ros = SMOTE()\n",
    "\n",
    "os_inputs, os_labels = ros.fit_resample(train_in, train_classes)\n",
    "\n",
    "print(Counter(os_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "\n",
    "dtc.fit(train_in, train_classes)\n",
    "dtc_prediction = dtc.predict(test_in)\n",
    "\n",
    "dtc_classification_report = classification_report(test_classes, dtc_prediction, output_dict=True)\n",
    "\n",
    "print(\"--- Original dataset ---\\n\")\n",
    "print(f\"Confusion matrix:\\n{confusion_matrix(test_classes, dtc_prediction)}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report(test_classes, dtc_prediction)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc.fit(us_inputs, us_labels)\n",
    "dtc_prediction = dtc.predict(test_in)\n",
    "\n",
    "dtc_us_classification_report = classification_report(test_classes, dtc_prediction, output_dict=True)\n",
    "\n",
    "print(\"--- Undersampled dataset ---\\n\")\n",
    "print(f\"Confusion matrix:\\n{confusion_matrix(test_classes, dtc_prediction)}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report(test_classes, dtc_prediction)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dtc.fit(os_inputs, os_labels)\n",
    "dtc_prediction = dtc.predict(test_in)\n",
    "\n",
    "dtc_os_classification_report = classification_report(test_classes, dtc_prediction, output_dict=True)\n",
    "\n",
    "print(\"--- Oversampled dataset ---\\n\")\n",
    "print(f\"Confusion matrix:\\n{confusion_matrix(test_classes, dtc_prediction)}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report(test_classes, dtc_prediction)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tunning (GridSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameter_grid = {'criterion': ['gini', 'entropy'],\n",
    "                  'splitter': ['best', 'random'],\n",
    "                  'max_depth': [11, 13, 15, 17],\n",
    "                  'max_features': [14, 15, 16, 17]}\n",
    "\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(),\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=10,\n",
    "                           verbose=4,\n",
    "                           n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(train_in, train_classes)\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best estimator: {grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = grid_search.best_estimator_\n",
    "dtc_prediction = dtc.predict(test_in)\n",
    "\n",
    "best_dtc_classification_report = classification_report(test_classes, dtc_prediction, output_dict=True)\n",
    "\n",
    "print(\"--- Improved original dataset ---\\n\")\n",
    "print(f\"Confusion matrix:\\n{confusion_matrix(test_classes, dtc_prediction)}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report(test_classes, dtc_prediction)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search.fit(us_inputs, us_labels)\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best estimator: {grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = grid_search.best_estimator_\n",
    "dtc_prediction = dtc.predict(test_in)\n",
    "\n",
    "best_us_dtc_classification_report = classification_report(test_classes, dtc_prediction, output_dict=True)\n",
    "\n",
    "print(\"--- Improved undersampled dataset ---\\n\")\n",
    "print(f\"Confusion matrix:\\n{confusion_matrix(test_classes, dtc_prediction)}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report(test_classes, dtc_prediction)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search.fit(os_inputs, os_labels)\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best estimator: {grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtc = grid_search.best_estimator_\n",
    "dtc_prediction = dtc.predict(test_in)\n",
    "\n",
    "best_os_dtc_classification_report = classification_report(test_classes, dtc_prediction, output_dict=True)\n",
    "\n",
    "print(\"--- Improved oversampled dataset ---\\n\")\n",
    "print(f\"Confusion matrix:\\n{confusion_matrix(test_classes, dtc_prediction)}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report(test_classes, dtc_prediction)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn.fit(train_in, train_classes)\n",
    "knn_prediction = knn.predict(test_in)\n",
    "\n",
    "knn_classification_report = classification_report(test_classes, knn_prediction, output_dict=True)\n",
    "\n",
    "print(\"--- Original dataset ---\\n\")\n",
    "print(f\"Confusion matrix:\\n{confusion_matrix(test_classes, knn_prediction)}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report(test_classes, knn_prediction)}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(us_inputs, us_labels)\n",
    "knn_prediction = knn.predict(test_in)\n",
    "\n",
    "knn_us_classification_report = classification_report(test_classes, knn_prediction, output_dict=True)\n",
    "\n",
    "print(\"--- Undersampled dataset ---\\n\")\n",
    "print(f\"Confusion matrix:\\n{confusion_matrix(test_classes, knn_prediction)}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report(test_classes, knn_prediction)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn.fit(os_inputs, os_labels)\n",
    "knn_prediction = knn.predict(test_in)\n",
    "\n",
    "knn_os_classification_report = classification_report(test_classes, knn_prediction, output_dict=True)\n",
    "\n",
    "print(\"--- Oversampled dataset ---\\n\")\n",
    "print(f\"Confusion matrix:\\n{confusion_matrix(test_classes, knn_prediction)}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report(test_classes, knn_prediction)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {'n_neighbors': [5, 8, 12, 15],\n",
    "                  'weights': ['uniform', 'distance'],\n",
    "                  'algorithm': ['ball_tree', 'kd_tree', 'brute']}\n",
    "\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(),\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=10,\n",
    "                           verbose=4,\n",
    "                           n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(train_in, train_classes)\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best estimator: {grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = grid_search.best_estimator_\n",
    "knn_prediction = knn.predict(test_in)\n",
    "\n",
    "best_knn_classification_report = classification_report(test_classes, knn_prediction, output_dict=True)\n",
    "\n",
    "print(\"--- Improved original dataset ---\\n\")\n",
    "print(f\"Confusion matrix:\\n{confusion_matrix(test_classes, knn_prediction)}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report(test_classes, knn_prediction)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search.fit(us_inputs, us_labels)\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best estimator: {grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = grid_search.best_estimator_\n",
    "knn_prediction = knn.predict(test_in)\n",
    "\n",
    "best_us_knn_classification_report = classification_report(test_classes, knn_prediction, output_dict=True)\n",
    "\n",
    "print(\"--- Improved undersampled dataset ---\\n\")\n",
    "print(f\"Confusion matrix:\\n{confusion_matrix(test_classes, knn_prediction)}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report(test_classes, knn_prediction)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(KNeighborsClassifier(),\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=5,\n",
    "                           verbose=4,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "grid_search.fit(os_inputs, os_labels)\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best estimator: {grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "knn = grid_search.best_estimator_\n",
    "knn_prediction = knn.predict(test_in)\n",
    "\n",
    "best_os_knn_classification_report = classification_report(test_classes, knn_prediction, output_dict=True)\n",
    "\n",
    "print(\"--- Improved oversampled dataset ---\\n\")\n",
    "print(f\"Confusion matrix:\\n{confusion_matrix(test_classes, knn_prediction)}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report(test_classes, knn_prediction)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support-vector machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "svc.fit(train_in, train_classes)\n",
    "svc_prediction = svc.predict(test_in)\n",
    "\n",
    "svc_classification_report = classification_report(test_classes, svc_prediction, output_dict=True)\n",
    "\n",
    "print(\"--- Original dataset ---\\n\")\n",
    "print(f\"Confusion matrix:\\n{confusion_matrix(test_classes, svc_prediction)}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report(test_classes, svc_prediction)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit(us_inputs, us_labels)\n",
    "svc_prediction = svc.predict(test_in)\n",
    "\n",
    "svc_us_classification_report = classification_report(test_classes, svc_prediction, output_dict=True)\n",
    "\n",
    "print(\"--- Undersampled dataset ---\\n\")\n",
    "print(f\"Confusion matrix:\\n{confusion_matrix(test_classes, svc_prediction)}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report(test_classes, svc_prediction)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "svc.fit(os_inputs, os_labels)\n",
    "svc_prediction = svc.predict(test_in)\n",
    "\n",
    "svc_os_classification_report = classification_report(test_classes, svc_prediction, output_dict=True)\n",
    "\n",
    "print(\"--- Oversampled dataset ---\\n\")\n",
    "print(f\"Confusion matrix:\\n{confusion_matrix(test_classes, svc_prediction)}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report(test_classes, svc_prediction)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {'C' : [0.1, 1, 10, 100], \n",
    "            'gamma' : ['scale', 'auto'],\n",
    "            'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(),\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=10,\n",
    "                           verbose=4,\n",
    "                           n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(train_in, train_classes)\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best estimator: {grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = grid_search.best_estimator_\n",
    "svc_prediction = svc.predict(test_in)\n",
    "\n",
    "best_svc_classification_report = classification_report(test_classes, svc_prediction, output_dict=True)\n",
    "\n",
    "print(\"--- Improved original dataset ---\\n\")\n",
    "print(f\"Confusion matrix:\\n{confusion_matrix(test_classes, svc_prediction)}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report(test_classes, svc_prediction)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search.fit(us_inputs, us_labels)\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best estimator: {grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = grid_search.best_estimator_\n",
    "svc_prediction = svc.predict(test_in)\n",
    "\n",
    "best_us_svc_classification_report = classification_report(test_classes, svc_prediction, output_dict=True)\n",
    "\n",
    "print(\"--- Improved undersampled dataset ---\\n\")\n",
    "print(f\"Confusion matrix:\\n{confusion_matrix(test_classes, svc_prediction)}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report(test_classes, svc_prediction)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search.fit(os_inputs, os_labels)\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best estimator: {grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svc = grid_search.best_estimator_\n",
    "svc_prediction = svc.predict(test_in)\n",
    "\n",
    "best_os_svc_classification_report = classification_report(test_classes, svc_prediction, output_dict=True)\n",
    "\n",
    "print(\"--- Improved oversampled dataset ---\\n\")\n",
    "print(f\"Confusion matrix:\\n{confusion_matrix(test_classes, svc_prediction)}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report(test_classes, svc_prediction)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "mlp.fit(train_in, train_classes)\n",
    "mlp_prediction = mlp.predict(test_in)\n",
    "\n",
    "mlp_classification_report = classification_report(test_classes, mlp_prediction, output_dict=True)\n",
    "\n",
    "print(\"--- Original dataset ---\\n\")\n",
    "print(f\"Confusion matrix:\\n{confusion_matrix(test_classes, mlp_prediction)}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report(test_classes, mlp_prediction)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.fit(us_inputs, us_labels)\n",
    "mlp_prediction = mlp.predict(test_in)\n",
    "\n",
    "mlp_us_classification_report = classification_report(test_classes, mlp_prediction, output_dict=True)\n",
    "\n",
    "print(\"--- Undersampled dataset ---\\n\")\n",
    "print(f\"Confusion matrix:\\n{confusion_matrix(test_classes, mlp_prediction)}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report(test_classes, mlp_prediction)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mlp.fit(os_inputs, os_labels)\n",
    "mlp_prediction = mlp.predict(test_in)\n",
    "\n",
    "mlp_os_classification_report = classification_report(test_classes, mlp_prediction, output_dict=True)\n",
    "\n",
    "print(\"--- Oversampled dataset ---\\n\")\n",
    "print(f\"Confusion matrix:\\n{confusion_matrix(test_classes, mlp_prediction)}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report(test_classes, mlp_prediction)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {'hidden_layer_sizes': [50, 100, 150],\n",
    "                  'activation' : ['identity', 'logistic', 'tanh', 'relu'],\n",
    "                  'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "                  'alpha': [0.0001, 0.001, 0.01]}\n",
    "\n",
    "grid_search = GridSearchCV(MLPClassifier(), \n",
    "                           param_grid=parameter_grid, \n",
    "                           cv=10,\n",
    "                           verbose=4,\n",
    "                           n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(train_in, train_classes)\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best estimator: {grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = grid_search.best_estimator_\n",
    "mlp_prediction = mlp.predict(test_in)\n",
    "\n",
    "best_mlp_classification_report = classification_report(test_classes, mlp_prediction, output_dict=True)\n",
    "\n",
    "print(\"--- Improved original dataset ---\\n\")\n",
    "print(f\"Confusion matrix:\\n{confusion_matrix(test_classes, mlp_prediction)}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report(test_classes, mlp_prediction)}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search.fit(us_inputs, us_labels)\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best estimator: {grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = grid_search.best_estimator_\n",
    "mlp_prediction = mlp.predict(test_in)\n",
    "\n",
    "best_us_mlp_classification_report = classification_report(test_classes, mlp_prediction, output_dict=True)\n",
    "\n",
    "print(\"--- Improved undersampled dataset ---\\n\")\n",
    "print(f\"Confusion matrix:\\n{confusion_matrix(test_classes, mlp_prediction)}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report(test_classes, mlp_prediction)}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search.fit(os_inputs, os_labels)\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best estimator: {grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlp = grid_search.best_estimator_\n",
    "mlp_prediction = mlp.predict(test_in)\n",
    "\n",
    "best_os_mlp_classification_report = classification_report(test_classes, mlp_prediction, output_dict=True)\n",
    "%store best_os_mlp_classification_report\n",
    "\n",
    "print(\"--- Improved oversampled dataset ---\\n\")\n",
    "print(f\"Confusion matrix:\\n{confusion_matrix(test_classes, mlp_prediction)}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report(test_classes, mlp_prediction)}\\n\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "9dd3c98d416b0b532d040c7c33706a2711858781af66a17ed364b3ea83b2b090"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
