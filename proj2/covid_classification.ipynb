{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covid Symptom Identification\n",
    "\n",
    "Project developed by:\n",
    "\n",
    "- Ana Teresa Cruz (up201806460)\n",
    "- André Nascimento (up201806461)\n",
    "- António Bezerra (up201806854)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('large_data.csv')\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "dataset_corr = dataset.corr()\n",
    "plt.figure(figsize=(30,30))\n",
    "sb.heatmap(dataset_corr, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All data hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.hist(bins=[-0.05, 0.05, 0.95, 1.05], range=(0,1), figsize=(22, 16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allergy data hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allergy_data = dataset.loc[dataset['TYPE'] == 'ALLERGY']\n",
    "allergy_data.hist(bins=[-0.05, 0.05, 0.95, 1.05], range=(0,1), figsize=(22,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cold data hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cold_data = dataset.loc[dataset['TYPE'] == 'COLD']\n",
    "cold_data.hist(bins=[-0.05, 0.05, 0.95, 1.05], range=(0,1), figsize=(22,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covid data hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_data = dataset.loc[dataset['TYPE'] == 'COVID']\n",
    "covid_data.hist(bins=[-0.05, 0.05, 0.95, 1.05], range=(0,1), figsize=(22,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flu data hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_data = dataset.loc[dataset['TYPE'] == 'FLU']\n",
    "flu_data.hist(bins=[-0.05, 0.05, 0.95, 1.05], range=(0,1), figsize=(22,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['TYPE'] = dataset['TYPE'].astype('category')\n",
    "\n",
    "col_names = list(dataset.columns)\n",
    "col_names.remove('TYPE')\n",
    "\n",
    "inputs = dataset[col_names].values\n",
    "labels = dataset['TYPE'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all types with 1024 samples\n",
    "us_dataset = pd.concat([allergy_data.sample(n=1024, random_state=1),\n",
    "                                  cold_data,\n",
    "                                  covid_data.sample(n=1024, random_state=1),\n",
    "                                  flu_data.sample(n=1024, random_state=1)])\n",
    "\n",
    "us_inputs = us_dataset[col_names].values\n",
    "us_labels = us_dataset['TYPE'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all types with 25000 samples\n",
    "os_dataset = pd.concat([allergy_data.sample(n=25000, replace=True, random_state=1),\n",
    "                                  cold_data.sample(n=25000, replace=True, random_state=1),\n",
    "                                  covid_data.sample(n=25000, replace=True, random_state=1),\n",
    "                                  flu_data])\n",
    "\n",
    "os_inputs = os_dataset[col_names].values\n",
    "os_labels = os_dataset['TYPE'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and Test split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(train_in,\n",
    " test_in,\n",
    " train_classes,\n",
    " test_classes) = train_test_split(inputs, labels, test_size=0.25, random_state=1, stratify=labels)\n",
    "\n",
    "(us_train_in,\n",
    " us_test_in,\n",
    " us_train_classes,\n",
    " us_test_classes) = train_test_split(us_inputs, us_labels, test_size=0.25, random_state=1, stratify=us_labels)\n",
    "\n",
    "(os_train_in,\n",
    " os_test_in,\n",
    " os_train_classes,\n",
    " os_test_classes) = train_test_split(os_inputs, os_labels, test_size=0.25, random_state=1, stratify=os_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(train_in)\n",
    "train_in = scaler.transform(train_in)\n",
    "test_in = scaler.transform(test_in) \n",
    "\n",
    "scaler.fit(us_train_in)\n",
    "us_train_in = scaler.transform(us_train_in)\n",
    "us_test_in = scaler.transform(us_test_in) \n",
    "\n",
    "scaler.fit(os_train_in)\n",
    "os_train_in = scaler.transform(os_train_in)\n",
    "os_test_in = scaler.transform(os_test_in) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "\n",
    "dtc.fit(train_in, train_classes)\n",
    "dtc_prediction = dtc.predict(test_in)\n",
    "\n",
    "dtc_confusion_matrix = confusion_matrix(test_classes, dtc_prediction)\n",
    "dtc_classification_report = classification_report(test_classes, dtc_prediction)\n",
    "\n",
    "print(f\"--- Original dataset ---\\nConfusion matrix:\\n{dtc_confusion_matrix}\\n\\nClassification report:\\n{dtc_classification_report}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc.fit(us_train_in, us_train_classes)\n",
    "dtc_prediction = dtc.predict(us_test_in)\n",
    "\n",
    "dtc_us_confusion_matrix = confusion_matrix(us_test_classes, dtc_prediction)\n",
    "dtc_us_classification_report = classification_report(us_test_classes, dtc_prediction)\n",
    "\n",
    "print(f\"--- Undersampled dataset ---\\nConfusion matrix:\\n{dtc_us_confusion_matrix}\\n\\nClassification report:\\n{dtc_us_classification_report}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtc.fit(os_train_in, os_train_classes)\n",
    "dtc_prediction = dtc.predict(os_test_in)\n",
    "\n",
    "dtc_os_confusion_matrix = confusion_matrix(os_test_classes, dtc_prediction)\n",
    "dtc_os_classification_report = classification_report(os_test_classes, dtc_prediction)\n",
    "\n",
    "print(f\"--- Oversampled dataset ---\\nConfusion matrix:\\n{dtc_os_confusion_matrix}\\n\\nClassification report:\\n{dtc_os_classification_report}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tunning (GridSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {'criterion': ['gini', 'entropy'],\n",
    "                  'splitter': ['best', 'random'],\n",
    "                  'max_depth': [11, 13, 15, 17],\n",
    "                  'max_features': [14, 15, 16, 17]}\n",
    "\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(),\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=10,\n",
    "                           verbose=3,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "grid_search.fit(train_in, train_classes)\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best estimator: {grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = grid_search.best_estimator_\n",
    "dtc_prediction = dtc.predict(test_in)\n",
    "\n",
    "\n",
    "best_dtc_confusion_matrix = confusion_matrix(test_classes, dtc_prediction)\n",
    "best_dtc_classification_report = classification_report(test_classes, dtc_prediction)\n",
    "\n",
    "\n",
    "print(f\"--- Improved original dataset ---\\nConfusion matrix:\\n{best_dtc_confusion_matrix}\\n\\nClassification report:\\n{best_dtc_classification_report}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search.fit(us_train_in, us_train_classes)\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best estimator: {grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = grid_search.best_estimator_\n",
    "dtc_prediction = dtc.predict(us_test_in)\n",
    "\n",
    "\n",
    "best_us_dtc_confusion_matrix = confusion_matrix(us_test_classes, dtc_prediction)\n",
    "best_us_dtc_classification_report = classification_report(us_test_classes, dtc_prediction)\n",
    "\n",
    "\n",
    "print(f\"--- Improved undersampled dataset ---\\nConfusion matrix:\\n{best_us_dtc_confusion_matrix}\\n\\nClassification report:\\n{best_us_dtc_classification_report}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search.fit(os_train_in, os_train_classes)\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best estimator: {grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtc = grid_search.best_estimator_\n",
    "dtc_prediction = dtc.predict(os_test_in)\n",
    "\n",
    "\n",
    "best_os_dtc_confusion_matrix = confusion_matrix(os_test_classes, dtc_prediction)\n",
    "best_os_dtc_classification_report = classification_report(os_test_classes, dtc_prediction)\n",
    "\n",
    "\n",
    "print(f\"--- Improved oversampled dataset ---\\nConfusion matrix:\\n{best_os_dtc_confusion_matrix}\\n\\nClassification report:\\n{best_os_dtc_classification_report}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest  !TODO!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_evaluate_RF(train_in, test_in, train_class, test_class):\n",
    "    rfClassifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42) # 10 decision trees used in this classifier\n",
    "    rfClassifier.fit(train_in, train_class)\n",
    "    \n",
    "    prediction = rfClassifier.predict(test_in)  #predict on test set\n",
    "    print(skmetric.confusion_matrix(test_class, prediction))\n",
    "    print(skmetric.classification_report(test_class, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn.fit(train_in, train_classes)\n",
    "knn_prediction = knn.predict(test_in)\n",
    "\n",
    "\n",
    "knn_confusion_matrix = confusion_matrix(test_classes, knn_prediction)\n",
    "knn_classification_report = classification_report(test_classes, knn_prediction)\n",
    "\n",
    "\n",
    "print(f\"--- Original dataset ---\\nConfusion matrix:\\n{knn_confusion_matrix}\\n\\nClassification report:\\n{knn_classification_report}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(us_train_in, us_train_classes)\n",
    "knn_prediction = knn.predict(us_test_in)\n",
    "\n",
    "knn_us_confusion_matrix = confusion_matrix(us_test_classes, knn_prediction)\n",
    "knn_us_classification_report = classification_report(us_test_classes, knn_prediction)\n",
    "\n",
    "print(f\"--- Undersampled dataset ---\\nConfusion matrix:\\n{knn_us_confusion_matrix}\\n\\nClassification report:\\n{knn_us_classification_report}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn.fit(os_train_in, os_train_classes)\n",
    "knn_prediction = knn.predict(os_test_in)\n",
    "\n",
    "knn_os_confusion_matrix = confusion_matrix(os_test_classes, knn_prediction)\n",
    "knn_os_classification_report = classification_report(os_test_classes, knn_prediction)\n",
    "\n",
    "print(f\"--- Oversampled dataset ---\\nConfusion matrix:\\n{knn_os_confusion_matrix}\\n\\nClassification report:\\n{knn_os_classification_report}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {'n_neighbors': [5, 8, 10, 12, 15],\n",
    "                  'weights': ['uniform', 'distance'],\n",
    "                  'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
    "\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(),\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=10,\n",
    "                           verbose=3,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "\n",
    "grid_search.fit(train_in, train_classes)\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best estimator: {grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = grid_search.best_estimator_\n",
    "knn_prediction = knn.predict(test_in)\n",
    "\n",
    "\n",
    "best_knn_confusion_matrix = confusion_matrix(test_classes, knn_prediction)\n",
    "best_knn_classification_report = classification_report(test_classes, knn_prediction)\n",
    "\n",
    "\n",
    "print(f\"--- Improved original dataset ---\\nConfusion matrix:\\n{best_knn_confusion_matrix}\\n\\nClassification report:\\n{best_knn_classification_report}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search.fit(us_train_in, us_train_classes)\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best estimator: {grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = grid_search.best_estimator_\n",
    "knn_prediction = svc.predict(us_test_in)\n",
    "\n",
    "\n",
    "best_us_knn_confusion_matrix = confusion_matrix(us_test_classes, knn_prediction)\n",
    "best_us_knn_classification_report = classification_report(us_test_classes, knn_prediction)\n",
    "\n",
    "\n",
    "print(f\"--- Improved undersampled dataset ---\\nConfusion matrix:\\n{best_us_knn_confusion_matrix}\\n\\nClassification report:\\n{best_us_knn_classification_report}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search.fit(os_train_in, os_train_classes)\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best estimator: {grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "knn = grid_search.best_estimator_\n",
    "knn_prediction = knn.predict(os_test_in)\n",
    "\n",
    "\n",
    "best_os_knn_confusion_matrix = confusion_matrix(os_test_classes, knn_prediction)\n",
    "best_os_knn_classification_report = classification_report(os_test_classes, knn_prediction)\n",
    "\n",
    "\n",
    "print(f\"--- Improved oversampled dataset ---\\nConfusion matrix:\\n{best_os_knn_confusion_matrix}\\n\\nClassification report:\\n{best_os_knn_classification_report}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support-vector machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "svc.fit(train_in, train_classes)\n",
    "svc_prediction = svc.predict(test_in)\n",
    "\n",
    "\n",
    "svc_confusion_matrix = confusion_matrix(test_classes, svc_prediction)\n",
    "svc_classification_report = classification_report(test_classes, svc_prediction)\n",
    "\n",
    "\n",
    "print(f\"--- Original dataset ---\\nConfusion matrix:\\n{svc_confusion_matrix}\\n\\nClassification report:\\n{svc_classification_report}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit(us_train_in, us_train_classes)\n",
    "svc_prediction = svc.predict(us_test_in)\n",
    "\n",
    "svc_us_confusion_matrix = confusion_matrix(us_test_classes, svc_prediction)\n",
    "svc_us_classification_report = classification_report(us_test_classes, svc_prediction)\n",
    "\n",
    "print(f\"--- Undersampled dataset ---\\nConfusion matrix:\\n{svc_us_confusion_matrix}\\n\\nClassification report:\\n{svc_us_classification_report}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "svc.fit(os_train_in, os_train_classes)\n",
    "svc_prediction = svc.predict(os_test_in)\n",
    "\n",
    "svc_os_confusion_matrix = confusion_matrix(os_test_classes, svc_prediction)\n",
    "svc_os_classification_report = classification_report(os_test_classes, svc_prediction)\n",
    "\n",
    "print(f\"--- Oversampled dataset ---\\nConfusion matrix:\\n{svc_os_confusion_matrix}\\n\\nClassification report:\\n{svc_os_classification_report}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {'C' : [0.1, 1, 10], \n",
    "            'gamma' : ['scale', 'auto'],\n",
    "            'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(),\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=10,\n",
    "                           verbose=3,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "grid_search.fit(train_in, train_classes)\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best estimator: {grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = grid_search.best_estimator_\n",
    "svc_prediction = svc.predict(test_in)\n",
    "\n",
    "\n",
    "best_svc_confusion_matrix = confusion_matrix(test_classes, svc_prediction)\n",
    "best_svc_classification_report = classification_report(test_classes, svc_prediction)\n",
    "\n",
    "\n",
    "print(f\"--- Improved original dataset ---\\nConfusion matrix:\\n{best_svc_confusion_matrix}\\n\\nClassification report:\\n{best_svc_classification_report}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search.fit(us_train_in, us_train_classes)\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best estimator: {grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = grid_search.best_estimator_\n",
    "svc_prediction = svc.predict(us_test_in)\n",
    "\n",
    "\n",
    "best_us_svc_confusion_matrix = confusion_matrix(us_test_classes, svc_prediction)\n",
    "best_us_svc_classification_report = classification_report(us_test_classes, svc_prediction)\n",
    "\n",
    "\n",
    "print(f\"--- Improved undersampled dataset ---\\nConfusion matrix:\\n{best_us_svc_confusion_matrix}\\n\\nClassification report:\\n{best_us_svc_classification_report}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search.fit(os_train_in, os_train_classes)\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best estimator: {grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svc = grid_search.best_estimator_\n",
    "svc_prediction = svc.predict(os_test_in)\n",
    "\n",
    "\n",
    "best_os_svc_confusion_matrix = confusion_matrix(os_test_classes, svc_prediction)\n",
    "best_os_svc_classification_report = classification_report(os_test_classes, svc_prediction)\n",
    "\n",
    "\n",
    "print(f\"--- Improved oversampled dataset ---\\nConfusion matrix:\\n{best_os_svc_confusion_matrix}\\n\\nClassification report:\\n{best_os_svc_classification_report}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "mlp.fit(train_in, train_classes)\n",
    "mlp_prediction = mlp.predict(test_in)\n",
    "\n",
    "\n",
    "mlp_confusion_matrix = confusion_matrix(test_classes, mlp_prediction)\n",
    "mlp_classification_report = classification_report(test_classes, mlp_prediction)\n",
    "\n",
    "\n",
    "print(f\"--- Original dataset ---\\nConfusion matrix:\\n{mlp_confusion_matrix}\\n\\nClassification report:\\n{mlp_classification_report}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.fit(us_train_in, us_train_classes)\n",
    "mlp_prediction = mlp.predict(us_test_in)\n",
    "\n",
    "mlp_us_confusion_matrix = confusion_matrix(us_test_classes, mlp_prediction)\n",
    "mlp_us_classification_report = classification_report(us_test_classes, mlp_prediction)\n",
    "\n",
    "print(f\"--- Undersampled dataset ---\\nConfusion matrix:\\n{mlp_us_confusion_matrix}\\n\\nClassification report:\\n{mlp_us_classification_report}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mlp.fit(os_train_in, os_train_classes)\n",
    "mlp_prediction = mlp.predict(os_test_in)\n",
    "\n",
    "mlp_os_confusion_matrix = confusion_matrix(os_test_classes, mlp_prediction)\n",
    "mlp_os_classification_report = classification_report(os_test_classes, mlp_prediction)\n",
    "\n",
    "print(f\"--- Oversampled dataset ---\\nConfusion matrix:\\n{mlp_os_confusion_matrix}\\n\\nClassification report:\\n{mlp_os_classification_report}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {'hidden_layer_sizes': [10, 50, 100],\n",
    "                  'activation' : ['identity', 'logistic', 'tanh', 'relu'],\n",
    "                  'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "                  'alpha': [0.0001, 0.001, 0.01]}\n",
    "\n",
    "grid_search = GridSearchCV(MLPClassifier(), \n",
    "                           param_grid=parameter_grid, \n",
    "                           cv=10,\n",
    "                           verbose=3,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "grid_search.fit(train_in, train_classes)\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best estimator: {grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = grid_search.best_estimator_\n",
    "mlp_prediction = mlp.predict(test_in)\n",
    "\n",
    "\n",
    "best_mlp_confusion_matrix = confusion_matrix(test_classes, mlp_prediction)\n",
    "best_mlp_classification_report = classification_report(test_classes, mlp_prediction)\n",
    "\n",
    "\n",
    "print(f\"--- Improved original dataset ---\\nConfusion matrix:\\n{best_mlp_confusion_matrix}\\n\\nClassification report:\\n{best_mlp_classification_report}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search.fit(us_train_in, us_train_classes)\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best estimator: {grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = grid_search.best_estimator_\n",
    "mlp_prediction = mlp.predict(us_test_in)\n",
    "\n",
    "\n",
    "best_us_mlp_confusion_matrix = confusion_matrix(us_test_classes, mlp_prediction)\n",
    "best_us_mlp_classification_report = classification_report(us_test_classes, mlp_prediction)\n",
    "\n",
    "\n",
    "print(f\"--- Improved undersampled dataset ---\\nConfusion matrix:\\n{best_us_mlp_confusion_matrix}\\n\\nClassification report:\\n{best_us_mlp_classification_report}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search.fit(os_train_in, os_train_classes)\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best estimator: {grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlp = grid_search.best_estimator_\n",
    "mlp_prediction = mlp.predict(os_test_in)\n",
    "\n",
    "\n",
    "best_os_mlp_confusion_matrix = confusion_matrix(os_test_classes, mlp_prediction)\n",
    "best_os_mlp_classification_report = classification_report(os_test_classes, mlp_prediction)\n",
    "\n",
    "\n",
    "print(f\"--- Improved oversampled dataset ---\\nConfusion matrix:\\n{best_os_mlp_confusion_matrix}\\n\\nClassification report:\\n{best_os_mlp_classification_report}\\n\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
